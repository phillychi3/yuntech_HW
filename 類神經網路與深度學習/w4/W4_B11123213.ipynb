{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[我的線上筆記連結.w.](https://app.heptabase.com/w/7ec6ef5bbaf4b1363f78e04e669381dcd754a217f1cb1a207c0a73354a984e2f)  "
      ],
      "metadata": {
        "id": "-SADP0Bzjxrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet\n",
        "\n",
        "AlexNet 是由 Alex Krizhevsky 於 2012 年提出的卷積神經網路，在同年的 ImageNet LSVRC 競賽中奪得冠軍，並將錯誤率從 26.2% 降低到 15.3%.\n",
        "\n",
        "AlexNet的幾個特點：\n",
        "\n",
        "- **更深的模型架構**：AlexNet 共有八層，包含五個卷積層和三個全連接層。\n",
        "\n",
        "- **更大的輸入層尺寸**：AlexNet 的輸入層尺寸為 224x224。\n",
        "\n",
        "- **更有效的卷積核**：使用了 11x11、5x5 和 3x3 的卷積核，可以更有效地提取影像的特徵。\n",
        "\n",
        "- **更快的激活函數**：使用了 ReLU 激活函數，\n",
        "\n",
        "- **降低 overfitting 的方法**：AlexNet 採用了 Dropout 和資料擴增等方法，可以有效降低 overfitting 的問題。\n",
        "\n",
        "# ResNet\n",
        "\n",
        "主要是透過**殘差學習，**就是學習輸入和輸出之間的殘差映射，而不是直接學習輸出。\n",
        "\n",
        "# 如何運行模型\n",
        "\n",
        "首先要將資料進行前處理，利如將圖片大小歸一化，並將圖片轉換成張量\n"
      ],
      "metadata": {
        "id": "J9knYtnkjy-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RcCrqxReNtxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaf5d7b-0095-4652-a501-763887619bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('golden retriever', 96.56639862060547)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torchvision import models\n",
        "with open('imagenet_classes.txt',\"r\") as f:\n",
        "  labels = [line.strip() for line in f]\n",
        "def what(img):\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "          mean =[0.488,0.456,0.406],\n",
        "          std=[0.229,0.224,0.225]\n",
        "      )\n",
        "  ])\n",
        "  resent = models.resnet101(pretrained=True)\n",
        "  resent.eval()\n",
        "  out = resent(torch.unsqueeze(preprocess(Image.open(img)),0))\n",
        "  index = torch.max(out,1)[1]\n",
        "  precentage = torch.nn.functional.softmax(out,dim=1)[0] * 100\n",
        "  precentage[index[0]].item()\n",
        "  return labels[index[0]],precentage[index[0]].item()\n",
        "print(what(\"bobby.jpg\"))"
      ]
    }
  ]
}